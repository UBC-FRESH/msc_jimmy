{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab0b3d94-f3e2-42b0-9d8e-ae85eae75afc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Forest estate model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ca48c-19e6-4e91-94c8-8565fbac96f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preamble\n",
    "\n",
    "Import modules, define classes and functions and constants, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0d73b-9a52-4fd2-8996-8fb53c6bf07a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git submodule init\n",
    "!git submodule update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03788f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install rasterio\n",
    "# %pip install fiona\n",
    "# %pip install gurobipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25bd33-2bc8-4490-9db6-cf5fc09b3367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install memory_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a464b45-7f41-4999-98fe-cdf84a361921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "module_path = os.path.abspath(os.path.join('ws3'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b956ab7-5bca-4d4a-a24e-7748f5c36622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae1c034-1849-4efb-9a88-dc8b3cd83a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ws3.forest, ws3.core\n",
    "import gurobipy as grb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from memory_profiler import profile\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4bd279-bfba-48c4-811e-5a1a4234e4a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'data/input'\n",
    "period_length = 1\n",
    "max_age = 500\n",
    "base_year = 2020\n",
    "horizon = 20\n",
    "model_name = 'tsa24_clipped'\n",
    "harvest_acode = 'cc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e3564b-a6b3-4809-906c-78dcd0ab8f58",
   "metadata": {},
   "source": [
    "# Create a new `ForestModel` instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23807df-6a53-4633-bb70-5acef0de2d77",
   "metadata": {},
   "source": [
    "The inputs files has been retrived from the model_input.ipynb. Following files are needed\n",
    "    - Landscape file\n",
    "    - Area file\n",
    "    - Growth and yield file\n",
    "    - Forest action file\n",
    "    - Transition rule file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b0041e-5d73-4057-975b-24c38d75fba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm = ws3.forest.ForestModel(model_name=model_name,\n",
    "                            model_path=data_path,\n",
    "                            base_year=base_year,\n",
    "                            horizon=horizon,\n",
    "                            period_length=period_length,\n",
    "                            max_age=max_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0958e12-f69d-49da-b8cb-cd3dd0748164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm.import_landscape_section()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ed8d8-b355-4f4f-84bd-98f43d493aad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm.import_areas_section()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035233f0-be6f-433a-b9ec-8166fbb202f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm.import_yields_section()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b3ae10-62ec-4a3e-a68d-d62bbfa02ad0",
   "metadata": {},
   "source": [
    "Note that we have to manually flag the `cc` action as a harvest action (or it will not pass the `is_harvest` gate in `cmp_c_z` when building the optimization model (and there will be no harvest volume to optimize, etc). Currently no way to do this automatically in the `import_actions_section` method, but will try to include something later to avoid having to remember to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6eb05-d6cf-4b28-9dd5-6b96d517aabd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm.import_actions_section()\n",
    "fm.actions[harvest_acode].is_harvest = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f748db-f77c-490c-a715-5c121a05cc16",
   "metadata": {},
   "source": [
    "Add a \"null\" action (does nothing). Needed for optimization functions to work. Sort of an obscure design, but that is the way ws3 is implemented for the moment so just roll with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25209f-8270-4bc6-8f8a-b018953a4dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm.add_null_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e94b98-1030-4060-b796-265742343828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm.import_transitions_section()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b5c8e-6ad4-43ca-babe-22f04d7d4889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm.compile_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2277313e-3986-422f-b97a-0b82c618bbc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm.initialize_areas()\n",
    "fm.reset_actions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d007d4-22d7-43e8-b814-31d85e22a28a",
   "metadata": {},
   "source": [
    "# Define scenario (add optimization problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392c7f8-6812-4fd4-821f-7d331b1964d9",
   "metadata": {},
   "source": [
    "First we need to define a few utility functions that we will use to build the problems (e.g., objective function coefficient function, even flow constraint coefficient function, general constraint coefficient function).\n",
    "\n",
    "Note that the `spades_ws3` project contains several useful chunks of code that you can use as a starting point (on GitHub, see link below).\n",
    "\n",
    "https://github.com/gparadis/spades_ws3/blob/master/python/spadesws3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dfbd31-ebe4-46e0-b4cd-1d768cb0f991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cmp_c_z(fm, path, expr):\n",
    "    \"\"\"\n",
    "    Compile objective function coefficient (given ForestModel instance, \n",
    "    leaf-to-root-node path, and expression to evaluate).\n",
    "    \"\"\"\n",
    "    result = 0.\n",
    "    for t, n in enumerate(path, start=1):\n",
    "        d = n.data()\n",
    "        if fm.is_harvest(d['acode']):\n",
    "            result += fm.compile_product(t, expr, d['acode'], [d['dtk']], d['age'], coeff=False)\n",
    "    return result\n",
    "\n",
    "def cmp_c_cflw(fm, path, expr, mask=None): # product, all harvest actions\n",
    "    \"\"\"\n",
    "    Compile flow constraint coefficient for product indicator (given ForestModel \n",
    "    instance, leaf-to-root-node path, expression to evaluate, and optional mask).\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for t, n in enumerate(path, start=1):\n",
    "        d = n.data()\n",
    "        if mask and not fm.match_mask(mask, d['dtk']): continue\n",
    "        if fm.is_harvest(d['acode']):\n",
    "            result[t] = fm.compile_product(t, expr, d['acode'], [d['dtk']], d['age'], coeff=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cmp_c_caa(fm, path, expr, acodes, mask=None): # product, named actions\n",
    "    \"\"\"\n",
    "    Compile constraint coefficient for product indicator (given ForestModel \n",
    "    instance, leaf-to-root-node path, expression to evaluate, list of action codes, \n",
    "    and optional mask).\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for t, n in enumerate(path, start=1):\n",
    "        d = n.data()\n",
    "        if mask and not fm.match_mask(mask, d['dtk']): continue\n",
    "        if d['acode'] in acodes:\n",
    "            result[t] = fm.compile_product(t, expr, d['acode'], [d['dtk']], d['age'], coeff=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cmp_c_ci(fm, path, yname, mask=None): # product, named actions\n",
    "    \"\"\"\n",
    "    Compile constraint coefficient for inventory indicator (given ForestModel instance, \n",
    "    leaf-to-root-node path, expression to evaluate, and optional mask).\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for t, n in enumerate(path, start=1):\n",
    "        d = n.data()\n",
    "        if mask and not fm.match_mask(mask, d['_dtk']): continue\n",
    "        result[t] = fm.inventory(t, yname=yname, age=d['_age'], dtype_keys=[d['_dtk']]) \n",
    "        #result[t] = fm.inventory(t, yname=yname, age=d['age'], dtype_keys=[d['dtk']]) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f6bbe-4ab5-4e96-bb35-70a415b8a171",
   "metadata": {},
   "source": [
    "Define a generic base scenario function, and link it to a dispatch function keyed on scenario name string (e.g., `base`). \n",
    "\n",
    "Note how we use `functools.partial` to specialize the more general functions defined above for use in the `coeff_funcs` arg of `ForestModel.add_problem`. Otherwise we would have to define an entirely new function each time we defined a slightly different objective or constraint in one of our scenarios, which would get tedious and messy. The tedium and mess would be more evident if we had a large number of alternative scenarios defined in the same notebook (which we do not here, but use your imagination). \n",
    "\n",
    "Note also that the expected data structures for the various args to `ForestModel.add_problem` must be matched exactly or `ws3` will likely crash somewhere in one of the series of complicated private optimization model-building methods that get called from `ForestModel.add_problem`. You _should not_ have to unpack the exact logic of this model-building code to figure out why your model is crashing... it really is quite complicated and hard to follow. If you model is crashing there, you probably fed invalid (or incorrectly structured) args to `ForestModel.add_problem`. Carefully review the structure and values of your args to find the problem. I left some notes below (and some comments in the `_gen_scen_base` function code) to help clarify the expected arg structure, and will work on expanding the docstrings in the `ws3` source code so this is less obscure going forward.\n",
    "\n",
    "I also had to patch the `ws3` code in two places so that it would \"grow\" correctly with the model set up to use _years_ as the age unit. For some reason the latest `dev` branch of `ws3` on GitHub was in some sort of intermediate state between using _periods_ and _years_ as the age unit. Originally `ws3` was implemented to import and simulate legacy Woodstock model input datasets, so it used _periods_ as the age unit (like Woodstock). At some point I think I hastily patched `ws3` to use _years_ as the age unit to make it work with `spades_ws3` for specific projects that needed to get done and delivered... if I recall we set the period length to 1 year for all those projects so it \"just worked\", but now we have a bit of a mess. Oops. Ultimately, I will need to revert `ws3` back to using Woodstock-compatible _period_ age unit (but make sure that the `spatial` module can still spatially and temporally disaggregate the aspatial periodic solutions from the Model I LP optimization problems into year-length time slices (maybe with age optionally expressed in years in output from this, for compatibility with downstream linked models like `SpaDES`). This is just a side-effect of many iterations of re-purposing `ws3` to work in a long (ad hoc) sequence of real research projects that had very specific input and output data specs. It is actually remarkable that `ws3` is not _more_ of a mess than it currently is, given the history and essentially null development budget. Use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba969b1b-1b62-4253-b517-ce37e3eb47de",
   "metadata": {},
   "source": [
    "`ForestModel.add_problem` arg specs are described below.\n",
    "\n",
    "`name`: String. Used as key to store `Problem` instances in a dict in the `ForestModel` instanace, so make sure it is unique within a given model or you will overwrite dict values (assuming you want to stuff multiple problems, and their solutions, into your model at the same time). \n",
    "    \n",
    "`coeff_funcs`: Dict of function references, keyed on _row name_ strings. These are the functions that generate the LP optimization problem matrix coefficients (for the objective function and constraint rows). This one gets complicated, and is a likely source of bugs. Make sure the row name key strings are all unique or you will make a mess. You can name the constraint rows anything you want, but the objective function row has to be named `z`. All coefficient functions must accept exactly two args, in this order: a `ws3.forest.ForestModel` instance and a `ws3.common.Path` instance. The `z` coefficient function is special in that it must return a single float value. All other (i.e., constraint) coefficient functions just return a dict of floats, keyed on period ints (can be sparse, i.e., not necessary to include key:value pairs in output dict if value is 0.0). It is useful (but not necessary) to use `functools.partial` to specialize a smaller number of more general function definitions (with more args, that get \"locked down\" and hidden by `partial`) as we have done in the example in this notebook.\n",
    "\n",
    "`cflw_e`: Dict of `(dict, int)` tuples, keyed on _row name_ strings (must match _row name_ key values used to define coefficient functions for flow constraints in `coeff_func` dict), where the int:float dict embedded in the tuple defines epsilon values keyed on periods (must include all periods, even if epsilon value is always the same). See example below. \n",
    "\n",
    "```\n",
    "{\n",
    "  'cflw_acut':({1:0.01, 2:0.01, ..., 10:0.01}, 1),\n",
    "  'cflw_vcut':({1:0.05, 2:0.05, ..., 10:0.05}, 1)\n",
    "}\n",
    "```\n",
    "\n",
    "`cgen_data`: Dict of dict of dicts. The outer-level dict is keyed on _row name_ strings (must match row names used in `coeff_funcs`. The middle second level of dicts always has keys `'lb'` and `'ub'`, and the inner level of dicts specifies lower- and upper-bound general constraint RHS (float) values, keyed on period (int).\n",
    "\n",
    "`acodes`: List of strings. Action codes to be included in optimization problem formulation (actions must defined in the `ForestModel` instance, but can be only a subset).\n",
    "\n",
    "`sense`: Must be one of `ws3.opt.SENSE_MAXIMIZE` or `ws3.opt.SENSE_MINIMIZE`.\n",
    "\n",
    "`mask`: Tuple of strings constituting a valid mask for your `ForestModel` instance. Can be `None` if you do not want to filter `DevelopmentType` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b81c76-47e0-4ca8-8525-4cced1c06934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name =[]\n",
    "def gen_scenario(fm, name=name, util=0.85, harvest_acode='cc', fert_acodes=[],\n",
    "                 cflw_ha={}, cflw_hv={}, \n",
    "                 cgen_gs={}, cgen_ha={}, cgen_hv={}, cgen_fa={},\n",
    "                 tvy_name='volume', obj_mode='max_hv', mask=None):\n",
    "    from functools import partial\n",
    "    import numpy as np\n",
    "    coeff_funcs = {}\n",
    "    cflw_e = {}\n",
    "    cgen_data = {}\n",
    "    acodes = ['null', harvest_acode] + fert_acodes # define list of action codes\n",
    "    vexpr = '%s * %0.2f' % (tvy_name, util) # define volume expression\n",
    "    if obj_mode == 'max_hv': # maximize harvest volume\n",
    "        sense = ws3.opt.SENSE_MAXIMIZE \n",
    "        zexpr = vexpr\n",
    "    elif obj_mode == 'min_ha': # minimize harvest area\n",
    "        sense = ws3.opt.SENSE_MINIMIZE \n",
    "        zexpr = '1.'\n",
    "    else:\n",
    "        raise ValueError('Invalid obj_mode: %s' % obj_mode)        \n",
    "    coeff_funcs['z'] = partial(cmp_c_z, expr=zexpr) # define objective function coefficient function  \n",
    "    T = fm.periods\n",
    "    if cflw_ha: # define even flow constraint (on harvest area)\n",
    "        cname = 'cflw_ha'\n",
    "        coeff_funcs[cname] = partial(cmp_c_caa, expr='1.', acodes=[harvest_acode], mask=None) \n",
    "        cflw_e[cname] = cflw_ha\n",
    "    if cflw_hv: # define even flow constraint (on harvest volume)\n",
    "        cname = 'cflw_hv'\n",
    "        coeff_funcs[cname] = partial(cmp_c_caa, expr=vexpr, acodes=[harvest_acode], mask=None) \n",
    "        cflw_e[cname] = cflw_hv         \n",
    "    if cgen_gs: # define general constraint (growing stock)\n",
    "        cname = 'cgen_gs'\n",
    "        coeff_funcs[cname] = partial(cmp_c_ci, yname=tvy_name, mask=None)\n",
    "        cgen_data[cname] = cgen_gs\n",
    "    if cgen_ha: # define general constraint (harvest area)\n",
    "        cname = 'cgen_ha'\n",
    "        coeff_funcs[cname] = partial(cmp_c_caa, expr='1.', acodes=[harvest_acode], mask=None) \n",
    "        cgen_data[cname] = cgen_ha\n",
    "    if cgen_hv: # define general constraint (harvest volume)\n",
    "        cname = 'cgen_hv'\n",
    "        coeff_funcs[cname] = partial(cmp_c_caa, expr=vexpr, acodes=[harvest_acode], mask=None) \n",
    "        cgen_data[cname] = cgen_hv\n",
    "    if cgen_fa: # define general constraint (fertilized area)\n",
    "        cname = 'cgen_fa'\n",
    "        coeff_funcs[cname] = partial(cmp_c_caa, expr='1.', acodes=fert_acodes, mask=None) \n",
    "        cgen_data[cname] = cgen_fa\n",
    "    return fm.add_problem(name, coeff_funcs, cflw_e, cgen_data=cgen_data, acodes=acodes, sense=sense, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65617f05-bcbe-4c2d-afca-a5df3525fe13",
   "metadata": {},
   "source": [
    "Define functions to compile scenario output into a dataframe, and plot this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb43b6-9787-4584-b157-f0184bda732b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compile_scenario(fm):\n",
    "    oha = [fm.compile_product(period, '1.', acode='cc') for period in fm.periods]\n",
    "    ohv = [fm.compile_product(period, 'volume * 0.85', acode='cc') for period in fm.periods]\n",
    "    ogs = [fm.inventory(period, 'volume') for period in fm.periods]\n",
    "    ofa11 = [fm.compile_product(period, '1.', acode='f11') for period in fm.periods] \n",
    "    ofa12 = [fm.compile_product(period, '1.', acode='f12') for period in fm.periods] \n",
    "    ofa13 = [fm.compile_product(period, '1.', acode='f13') for period in fm.periods] \n",
    "    ofa14 = [fm.compile_product(period, '1.', acode='f14') for period in fm.periods] \n",
    "    ofa15 = [fm.compile_product(period, '1.', acode='f15') for period in fm.periods] \n",
    "    ofa16 = [fm.compile_product(period, '1.', acode='f16') for period in fm.periods] \n",
    "    ofa17 = [fm.compile_product(period, '1.', acode='f17') for period in fm.periods] \n",
    "    ofa21 = [fm.compile_product(period, '1.', acode='f21') for period in fm.periods] \n",
    "    ofa22 = [fm.compile_product(period, '1.', acode='f22') for period in fm.periods] \n",
    "    ofa23 = [fm.compile_product(period, '1.', acode='f23') for period in fm.periods] \n",
    "    ofa24 = [fm.compile_product(period, '1.', acode='f24') for period in fm.periods] \n",
    "    ofa25 = [fm.compile_product(period, '1.', acode='f25') for period in fm.periods] \n",
    "    ofa26 = [fm.compile_product(period, '1.', acode='f26') for period in fm.periods] \n",
    "    ofa31 = [fm.compile_product(period, '1.', acode='f31') for period in fm.periods] \n",
    "    ofa32 = [fm.compile_product(period, '1.', acode='f32') for period in fm.periods] \n",
    "    ofa33 = [fm.compile_product(period, '1.', acode='f33') for period in fm.periods] \n",
    "    ofa34 = [fm.compile_product(period, '1.', acode='f34') for period in fm.periods] \n",
    "    ofa35 = [fm.compile_product(period, '1.', acode='f35') for period in fm.periods]\n",
    "    data = {'period':fm.periods, \n",
    "            'oha':oha, \n",
    "            'ohv':ohv, \n",
    "            'ogs':ogs, \n",
    "            'ofa11':ofa11, \n",
    "            'ofa12':ofa12, \n",
    "            'ofa13':ofa13, \n",
    "            'ofa14':ofa14, \n",
    "            'ofa15':ofa15, \n",
    "            'ofa16':ofa16, \n",
    "            'ofa17':ofa17, \n",
    "            'ofa21':ofa21, \n",
    "            'ofa22':ofa22, \n",
    "            'ofa23':ofa23, \n",
    "            'ofa24':ofa24, \n",
    "            'ofa25':ofa25, \n",
    "            'ofa26':ofa26, \n",
    "            'ofa31':ofa31, \n",
    "            'ofa32':ofa32, \n",
    "            'ofa33':ofa33, \n",
    "            'ofa34':ofa34, \n",
    "            'ofa35':ofa35}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bdac1-b278-420f-aade-2a6a2ff48048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_scenario(df):\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    ax[0].bar(df.period, df.oha)\n",
    "    ax[0].set_ylim(0, None)\n",
    "    ax[0].set_title('Harvested area (ha)')\n",
    "    ax[1].bar(df.period, df.ohv)\n",
    "    ax[1].set_ylim(0, None)\n",
    "    ax[1].set_title('Harvested volume (m3)')\n",
    "    ax[2].bar(df.period, df.ogs)\n",
    "    ax[2].set_ylim(0, None)\n",
    "    ax[2].set_title('Growing Stock (m3)')\n",
    "    ax[3].bar(df.period, df.ofa11, color='blue', alpha=0.5)\n",
    "    ax[3].bar(df.period, df.ofa12, color='yellow', alpha=0.5)\n",
    "    ax[3].bar(df.period, df.ofa13, color='blue', alpha=0.5)\n",
    "    ax[3].bar(df.period, df.ofa14, color='blue', alpha=0.5)\n",
    "    ax[3].bar(df.period, df.ofa15, color='red')\n",
    "    ax[3].bar(df.period, df.ofa16, color='blue', alpha=0.5)\n",
    "    ax[3].bar(df.period, df.ofa17, color='blue', alpha=0.5)\n",
    "    # ax[3].bar(df.period, df.ofa21, color='blue', alpha=0.5)\n",
    "    # ax[3].bar(df.period, df.ofa22, color='blue', alpha=0.5)\n",
    "    # ax[3].bar(df.period, df.ofa23, color='blue', alpha=0.5)\n",
    "    # ax[3].bar(df.period, df.ofa24, color='blue', alpha=0.5)\n",
    "    ax[3].bar(df.period, df.ofa25, color='orange')\n",
    "    ax[3].bar(df.period, df.ofa26, color='blue', alpha=0.5)\n",
    "    ax[3].bar(df.period, df.ofa31, color='blue', alpha=0.5)\n",
    "    ax[3].bar(df.period, df.ofa32, color='blue', alpha=0.5)\n",
    "    ax[3].bar(df.period, df.ofa33, color='blue', alpha=0.5)\n",
    "    ax[3].bar(df.period, df.ofa34, color='blue', alpha=0.5)\n",
    "    ax[3].bar(df.period, df.ofa35, color='yellow')\n",
    "    #ax[3].legend(fert_acodes)\n",
    "    ax[3].set_ylim(0, None)\n",
    "    ax[3].set_title('Fertilized Area (ha)')\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c508f3a3-9e1c-48f3-892e-85fe04fc6b7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747614a4-3cae-46f7-b146-6255faf66002",
   "metadata": {},
   "source": [
    "We define some scenario options below. Specify which scenario by setting the `scenario_name` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2bef5-8b3d-49c6-afd0-43c5d99362ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open('scenario.json', 'r') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# # Edit the data\n",
    "# data['scenario_name'] = 'base'\n",
    "# data['inventory_retention'] = 1\n",
    "# data['clt_percentage'] = 0.2\n",
    "\n",
    "# scenario_name = data[\"scenario_name\"]\n",
    "# inventory_retention = data[\"inventory_retention\"]\n",
    "# clt_percentage = data[\"clt_percentage\"]\n",
    "\n",
    "# # Write the updated data back to the JSON file\n",
    "# with open('scenario.json', 'w') as f:\n",
    "#     json.dump(data, f, indent=4)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d78ee1-217e-44d0-86be-f2d990345c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scenario_name = 'base'\n",
    "# scenario_name = 'fert_once'\n",
    "# scenario_name = 'fert_twice'\n",
    "# scenario_name = 'fert_thrice'\n",
    "# scenario_name = 'fert_age10'\n",
    "# scenario_name = 'f35'\n",
    "# scenario_name = 'fert_age20'\n",
    "# scenario_name = 'fert_age30'\n",
    "# scenario_name = 'fert_age40'\n",
    "# scenario_name = 'fert_age50'\n",
    "# scenario_name = 'fert_age60'\n",
    "# scenario_name = 'fert_age70'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b22489-1842-4456-b0f6-43ccc241c9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cflw_ha = {}\n",
    "cflw_hv = {}\n",
    "cgen_gs = {}\n",
    "cgen_ha = {}\n",
    "cgen_hv = {}\n",
    "cgen_fa = {}\n",
    "fert_acodes = []\n",
    "\n",
    "\n",
    "# define growing stock general constraints\n",
    "inventory_retention = 1\n",
    "cgen_gs = {'lb':{x:140000. * inventory_retention for x in range(10,21)}, 'ub':{y:142000. * inventory_retention for y in [20]}}   \n",
    "# cgen_gs = {'lb':{x:140000. * inventory_retention for x in [20]}, 'ub':{y:150000. * inventory_retention for y in fm.periods}} \n",
    "# cgen_gs = {'lb':{p:20000. for p in fm.periods}, 'ub':{p:1000000. for p in fm.periods}}    \n",
    "\n",
    "# define harvest area and harvest volume flow constraints\n",
    "# cflw_ha = ({p:0.05 for p in fm.periods}, 10)\n",
    "cflw_hv = ({p:0.05 for p in fm.periods}, 10)\n",
    "\n",
    "# define harvest area and harvest volume general constraints\n",
    "cgen_ha = {'lb':{20:100}, 'ub':{20:150}}    \n",
    "# cgen_ha = {'lb':{x:0 for x in fm.periods}, 'ub':{y:0 for y in fm.periods}}    \n",
    "\n",
    "# cgen_hv = {'lb':{x:17500 for x in fm.periods}, 'ub':{y:18000 for y in fm.periods}}    \n",
    "\n",
    "# define fertilized area general constraints\n",
    "# cgen_fa = {'lb':{p:50 for p in fm.periods}, 'ub':{p:200 for p in fm.periods}}    \n",
    "\n",
    "\n",
    "if scenario_name == 'base': \n",
    "    # Base scenario\n",
    "    fert_acodes = []\n",
    "elif scenario_name == 'fert_once': \n",
    "    # Base scenario, plus one-application fertilization actions\n",
    "    fert_acodes=['f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17']\n",
    "elif scenario_name == 'fert_twice': \n",
    "    # Base scenario, plus two-application fertilization actions\n",
    "    fert_acodes=['f21', 'f22', 'f23', 'f24', 'f25', 'f26']\n",
    "elif scenario_name == 'fert_thrice': \n",
    "    # Base scenario, plus three-application fertilization actions\n",
    "    fert_acodes=['f31', 'f32', 'f33', 'f34']\n",
    "# elif scenario_name == 'fert_thrice': \n",
    "#     # Base scenario, plus three-application fertilization actions\n",
    "#     fert_acodes=['f31', 'f32', 'f33', 'f34', 'f35']\n",
    "elif scenario_name == 'fert_age10': \n",
    "    # Base scenario, plus age-10 fertilization actions\n",
    "    fert_acodes=['f11', 'f21', 'f31']\n",
    "elif scenario_name == 'f31': \n",
    "    # Base scenario, plus age-10 fertilization actions\n",
    "    fert_acodes=['f31']\n",
    "elif scenario_name == 'f32': \n",
    "    # Base scenario, plus age-10 fertilization actions\n",
    "    fert_acodes=['f32']\n",
    "elif scenario_name == 'f33': \n",
    "    # Base scenario, plus age-10 fertilization actions\n",
    "    fert_acodes=['f33']\n",
    "elif scenario_name == 'f34': \n",
    "    # Base scenario, plus age-10 fertilization actions\n",
    "    fert_acodes=['f34']\n",
    "elif scenario_name == 'f35': \n",
    "    # Base scenario, plus age-10 fertilization actions\n",
    "    fert_acodes=['f35']\n",
    "elif scenario_name == 'fert_age20': \n",
    "    # Base scenario, plus age-20 fertilization actions\n",
    "    fert_acodes=['f12', 'f22', 'f32']\n",
    "elif scenario_name == 'fert_age30': \n",
    "    # Base scenario, plus age-30 fertilization actions\n",
    "    fert_acodes=['f13', 'f23', 'f33']\n",
    "elif scenario_name == 'fert_age40': \n",
    "    # Base scenario, plus age-40 fertilization actions\n",
    "    fert_acodes=['f14', 'f24', 'f34']\n",
    "elif scenario_name == 'fert_age50': \n",
    "    # Base scenario, plus age-50 fertilization actions\n",
    "    fert_acodes=['f15', 'f25', 'f35']\n",
    "elif scenario_name == 'fert_age60': \n",
    "    # Base scenario, plus age-60 fertilization actions\n",
    "    fert_acodes=['f16', 'f26']\n",
    "elif scenario_name == 'fert_age70': \n",
    "    # Base scenario, plus age-70 fertilization actions\n",
    "    fert_acodes=['f17']\n",
    "\n",
    "%memit\n",
    "%time\n",
    "\n",
    "p = gen_scenario(fm=fm, \n",
    "                 name=scenario_name, \n",
    "                 fert_acodes=fert_acodes, \n",
    "                 cflw_ha=cflw_ha, \n",
    "                 cflw_hv=cflw_hv,\n",
    "                 cgen_gs=cgen_gs,\n",
    "                 cgen_ha=cgen_ha,\n",
    "                 cgen_hv=cgen_hv,\n",
    "                 cgen_fa=cgen_fa)\n",
    "\n",
    "%memit\n",
    "%time\n",
    "# fm.reset()\n",
    "# m = p.solve()\n",
    "# sch = fm.compile_schedule(p)\n",
    "# fm.apply_schedule(sch, \n",
    "#                   force_integral_area=False, \n",
    "#                   override_operability=False,\n",
    "#                   fuzzy_age=False,\n",
    "#                   recourse_enabled=False,\n",
    "#                   verbose=False,\n",
    "#                   compile_c_ycomps=True)\n",
    "# df = compile_scenario(fm)\n",
    "# path = os.path.join('.', 'model_result')\n",
    "# filename = save_document + '.csv'\n",
    "# filepath = os.path.join(path, filename)\n",
    "# df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f156a50-d21d-4a73-8ca7-6c66c2f55c60",
   "metadata": {},
   "source": [
    "You will need to have `gurobipy` installed for this next step to work. At some point I will finish implementing bindings to the PuLP open-source solver library, but for now we are stuck with Gurobi as the only solver that works with ws3. \n",
    "\n",
    "You should be able to install `gurobipy` using the magic `%pip` command below, however this _only_ installs the Python module and minimal solver binaries. This _does not_ install the full Gurobi software stack, do the Gurobi licence managent tools (including the `grbgetkey` command) are _not_ installed automatically with the Python module. The `gurobipy` installation includes a limited software license that should allow you to solve _small_ problem instances, but will puke if you try to solve anything too large (which includes most `ws3` problems, unless you model is extremely small and simple). \n",
    "\n",
    "If you are eligible for an academic license, you should request and install a \"Named-User Acacdemic\" license from the Licenses tab in the [Gurobi User Portal](https://portal.gurobi.com/iam/licenses/request) (create a new Gurobi account if you do not have one yet, using your official academic institution email address). This license is per-user, per-machine, is valid for one year, should _only_ be used in an academic context (see [Gurobi Standard EULA](https://cdn.gurobi.com/wp-content/uploads/Gurobi_Standard_EULA_Nov2022.pdf) for details of license terms and restrictions).\n",
    "\n",
    "**Hint:** If you get a `grbgetkey: command not found` error, either the full Gurobi software stack is not installed at all on your system, or is installed but `grbgetkey` is not in your path. Depending on your situation, either [install the full Gurobi software stack](https://support.gurobi.com/hc/en-us/articles/4534161999889) or specify the full path to the `grbgetkey` command (I usually install Gurobi in `/opt/gurobi` when setting up my development VMs).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f831547-c224-465e-8b03-27f417cd5e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7311db-b40b-49a8-8ba4-345bf22f5786",
   "metadata": {},
   "source": [
    "Solve the optimization problem. Note that we stash a reference to the lower-level `gurobi.Model` object in case we need or want to poke around it (can yield insight into how the optimization problem is formulated on the solver side of things, or help debug).\n",
    "\n",
    "Be vigilant for \"infeasible or unbounded model\" messages and such below, in case these are unexpected. Depending on how the rest of the model was set up, `ws3` may automatically attempt to resolve infeasible models using \"feasibility relaxation\" mode in Gurobi (which might not be what you want, depending on the situation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21162ccf-b6b6-465b-a7fb-79b7262e1dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = p.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c2b378-70dc-481d-93e6-72cb51e50a90",
   "metadata": {},
   "source": [
    "If the model solved to optimality, simulate the optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336038ba-b334-41cc-b5e1-572764e1eec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if m.status != grb.GRB.OPTIMAL:\n",
    "    print('Model not optimal.')\n",
    "    sys.exit()\n",
    "sch = fm.compile_schedule(p)\n",
    "fm.apply_schedule(sch, \n",
    "                  force_integral_area=False, \n",
    "                  override_operability=False,\n",
    "                  fuzzy_age=False,\n",
    "                  recourse_enabled=False,\n",
    "                  verbose=False,\n",
    "                  compile_c_ycomps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33abfe90-86ae-4f1d-b265-a99b699b2df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = compile_scenario(fm)\n",
    "mean_volume = df['ohv'].mean()\n",
    "print(mean_volume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78456d3-3f32-4531-ba77-744187203249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d24a6-966f-45e0-9037-97505e58cf73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c6b0b-27c4-42f7-8b18-03242ff17ed3",
   "metadata": {},
   "source": [
    "# Convert the management pland and HWP volume into csv document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f0c37-41df-4189-bd1b-43b557df35cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extracted_columns = df[['period', 'oha']]\n",
    "\n",
    "df['summary'] = df[['ofa11', 'ofa12', 'ofa13', 'ofa14', 'ofa15', 'ofa16', 'ofa17', 'ofa21', 'ofa22', 'ofa23', 'ofa24', 'ofa25', 'ofa26', 'ofa31', 'ofa32', 'ofa33', 'ofa34', 'ofa35']].sum(axis=1)\n",
    "\n",
    "df_operation_area = extracted_columns.copy()\n",
    "df_operation_area['fert_area'] = df['summary']\n",
    "\n",
    "df_operation_area.to_csv(f\"model_result/emission_calculation/operation_area_{scenario_name}.csv\")\n",
    "df_operation_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab5d322-1f5b-4481-8910-43e8ddd1fc42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(f\"model_result/management_plan/management_plan_{scenario_name}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fd09c-61e8-4c62-acb1-13865195fc12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_product = {\n",
    "    'period': fm.periods,\n",
    "    'volume': [fm.compile_product(i, 'volume') for i in fm.periods],\n",
    "    'plumber': [fm.compile_product(i, 'plumber') * 0.0023597372 for i in fm.periods],\n",
    "    'pbark': [fm.compile_product(i, 'pbark') for i in fm.periods],\n",
    "    'pchips': [fm.compile_product(i, 'pchips') for i in fm.periods],\n",
    "    'psawdust': [fm.compile_product(i, 'psawdust') for i in fm.periods],\n",
    "    'pshaving': [fm.compile_product(i, 'pshaving') for i in fm.periods],\n",
    "    'ptrim': [fm.compile_product(i, 'ptrim') for i in fm.periods]\n",
    "}\n",
    "\n",
    "df_product = pd.DataFrame(data_product)\n",
    "\n",
    "df_product.drop('volume', axis=1, inplace=True)\n",
    "# df_product.to_csv(f\"model_result/hwp_volume/hwp_volume_{scenario_name}.csv\")\n",
    "# df_product.to_csv(f\"model_result/emission_calculation/hwp_volume_{scenario_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae195c51-ce23-4a85-a2de-e02442afb247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce9a889-55a2-4340-9f73-be7dcb943b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# path = os.path.join('.', 'model_result')\n",
    "# filename = save_document + '.csv'\n",
    "# filepath = os.path.join(path, filename)\n",
    "# df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c92b93b-c35f-45de-8e37-fea3ce60566d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_scenario(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c487be-97cf-4ac4-a346-320f0397fb19",
   "metadata": {},
   "source": [
    "## Carbon sequestration calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e8720-7478-414e-bbbc-6700ce41cca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_carbon_seq = {'period': [], 'co2_seq': []}\n",
    "\n",
    "for i in range(1, 21):\n",
    "    period_value = i\n",
    "    if i == 1:\n",
    "        co2_value = fm.compile_product(i, 'volume') * 460 * 0.5 * 44 / 12 #0.5 is the average carbon intensity for wood and convert carbon content to co2 eq\n",
    "        data_carbon_seq['period'].append(period_value)\n",
    "        data_carbon_seq['co2_seq'].append(co2_value)\n",
    "    else:    \n",
    "        co2_value = (fm.compile_product(i, 'volume') + fm.inventory(i, 'volume') - fm.inventory(i - 1, 'volume')) * 460 * 0.5 * 44 / 12 #0.5 is the average carbon intensity for wood\n",
    "\n",
    "        data_carbon_seq['period'].append(period_value)\n",
    "        data_carbon_seq['co2_seq'].append(co2_value)\n",
    "    \n",
    "df_carbon_seq = pd.DataFrame(data_carbon_seq)\n",
    "# df_carbon_seq.to_csv(f\"model_result/emission_calculation/co2_sequestration_{scenario_name}.csv\")\n",
    "df_carbon_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457fa6c-ff43-466f-ab7f-84d32ec5e7c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm.inventory(1,'volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9743a3fd-c30e-4786-8ac3-cf52cfbddce9",
   "metadata": {},
   "source": [
    "## The following section is the CBM sequential running section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e9edbc-bffe-4e71-93f7-80cc6f581c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import libcbm\n",
    "libcbm.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34510dec-e51e-4bc6-b71e-c1e9131714cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_classifier_colname = 'species'\n",
    "leading_species_classifier_colname = 'leading_species'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a843bc4-c39f-4a29-95ea-cba690d689e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = 300 # this MIGHT have to match the number of ages classes in sit_age_classes (not sure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2120e83c-8078-40d6-9c4e-6462f93b81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'theme0':[], 'theme1':[], 'theme2':[], 'theme3':[], 'theme4':[], \n",
    "        species_classifier_colname:[], leading_species_classifier_colname:[], \n",
    "        **{'v%i' % i:[] for i in range(nv + 1)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccd2b8a-0fc8-46f3-a5d9-4da4e616ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "canfi_species = pd.read_csv('data/canfi_species.csv')\n",
    "canfi_species.set_index('canfi_species', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a85055-ec01-422f-8d35-86a8bbfed8db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "leading_species_from_dtype_key = {} # we will need this later (as leading_species needs to be a \"classifier\" in libcbm\n",
    "\n",
    "for dtype_key, ytype, curves in fm.yields[:-1]:\n",
    "    if ytype != 'a': continue\n",
    "    for yname, curve in curves:\n",
    "        if yname.startswith('s'):\n",
    "            for i in range(5): data['theme%i' % i].append(dtype_key[i])\n",
    "            species = 'softwood' if int(yname[-4:]) < 1200 else 'hardwood' # CANFI species codes happen to be sorted by softwood/hardwood \n",
    "            leading_species_from_dtype_key[dtype_key] = species\n",
    "            data[species_classifier_colname].append(species)\n",
    "            data[leading_species_classifier_colname].append(species) # just a weird libcbm data model thing...\n",
    "            #data['foo'].append(species)\n",
    "            #data['bar'].append(species) # just a weird libcbm data model thing...\n",
    "            # for i in range(nv + 1): data['v%i' % i].append(curve[i * 10])\n",
    "            for i in range(nv + 1): data['v%i' % i].append(curve[i] * 0.87)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ce686-503f-499d-8a70-2f14ad158ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sit_yield = pd.DataFrame(data)\n",
    "sit_yield.to_csv('data_cbm/sit_yield.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d850b-01a8-45ee-b0c7-45ac2e958c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sit_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12fe87d-1ff7-4764-8a81-b2e62d3bd86d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names = ['_', 'theme0', 'theme1', 'theme2', 'theme3', 'theme4', 'age', 'area']\n",
    "sit_inventory = pd.read_csv('data/woodstock_model_files/tsa24_clipped.are', \n",
    "                            delimiter=' ', header=None, names=names)\n",
    "# sit_inventory['theme4'] = sit_inventory['theme4'].astype(int)\n",
    "\n",
    "sit_inventory['theme4'] = sit_inventory['theme4'].apply(lambda x: x + 20000 if x < 2420000 else x)\n",
    "sit_inventory.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175bb1fc-5864-48e0-9f31-05b670177813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sit_inventory.drop('_', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a28f9-a027-4e4c-9de5-144cf48d7c44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _leading_species(dtype_key):\n",
    "    for mask, leading_species in leading_species_from_dtype_key.items():\n",
    "        if fm.match_mask(mask, dtype_key):\n",
    "            return leading_species\n",
    "        \n",
    "def __leading_species(r):\n",
    "    dtype_key = tuple(str(r['theme%i' % i]) for i in range(5))\n",
    "    return _leading_species(dtype_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d1ea67-9ddd-4a6e-b4f1-d364c002b21a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sit_inventory[species_classifier_colname] = sit_inventory.apply(__leading_species, axis=1)\n",
    "sit_inventory['theme3'] = sit_inventory['theme3'].astype(int)  # Convert 'theme3' column to integers\n",
    "\n",
    "sit_inventory['species'] = sit_inventory['theme3'].apply(lambda x: 'softwood' if x < 1200 else 'hardwood')\n",
    "\n",
    "sit_inventory['using_age_class'] = 'FALSE'\n",
    "sit_inventory['delay'] = 0\n",
    "sit_inventory['landclass'] = 0\n",
    "sit_inventory['historic_disturbance'] = 'fire'\n",
    "sit_inventory['last_pass_disturbance'] = sit_inventory.apply(lambda r: 'fire' if r['theme2'] == r['theme4'] else 'harvest', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c62e0f-9e28-4dc5-827c-3889e46ea846",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names = ['theme0', 'theme1', 'theme2', 'theme3', 'theme4', species_classifier_colname,\n",
    "         'using_age_class', 'age', 'area', 'delay', 'landclass', \n",
    "         'historic_disturbance', 'last_pass_disturbance']\n",
    "sit_inventory = sit_inventory[names]\n",
    "sit_inventory = sit_inventory[sit_inventory['theme1'] != 0]\n",
    "# sit_inventory['age'] = (sit_inventory['age']/10).round()\n",
    "# sit_inventory['age'] = sit_inventory['age']\n",
    "sit_inventory['age'] = np.round(sit_inventory['age'], -1)-10\n",
    "sit_inventory.to_csv('data_cbm/sit_inventory.csv', index=False)\n",
    "sit_inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3dbca8-70b1-43bc-903a-4d8d3e9b99df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {'classifier_id':[], 'name':[], 'description':[]}\n",
    "for i in range(5):\n",
    "    data['classifier_id'].append(i+1)\n",
    "    data['name'].append('_CLASSIFIER')\n",
    "    data['description'].append('theme%i' % i)\n",
    "    for v in fm.theme_basecodes(i):\n",
    "        data['classifier_id'].append(i+1)\n",
    "        data['name'].append(v)\n",
    "        data['description'].append(v) # these are not very good descriptions, but will not affect CBM model output\n",
    "\n",
    "        \n",
    "# ['2401000' '2401002' '2402000' '2402002' '2402005' '2403000' '2403002']\n",
    "data['classifier_id'].append(5)\n",
    "data['name'].append('2401000')\n",
    "data['description'].append('2401000') \n",
    "\n",
    "data['classifier_id'].append(5)\n",
    "data['name'].append('2401002')\n",
    "data['description'].append('2401002')\n",
    "\n",
    "data['classifier_id'].append(5)\n",
    "data['name'].append('2402000')\n",
    "data['description'].append('2402000') \n",
    "\n",
    "data['classifier_id'].append(5)\n",
    "data['name'].append('2402002')\n",
    "data['description'].append('2402002') \n",
    "\n",
    "data['classifier_id'].append(5)\n",
    "data['name'].append('2402005')\n",
    "data['description'].append('2402005') \n",
    "\n",
    "data['classifier_id'].append(5)\n",
    "data['name'].append('2403000')\n",
    "data['description'].append('2403000')\n",
    "\n",
    "data['classifier_id'].append(5)\n",
    "data['name'].append('2403002')\n",
    "data['description'].append('2403002') \n",
    "\n",
    "\n",
    "data['classifier_id'].append(6)\n",
    "data['name'].append('_CLASSIFIER')\n",
    "data['description'].append(species_classifier_colname) \n",
    "\n",
    "data['classifier_id'].append(6)\n",
    "data['name'].append('softwood')\n",
    "data['description'].append('softwood') \n",
    "\n",
    "data['classifier_id'].append(6)\n",
    "data['name'].append('hardwood')\n",
    "data['description'].append('hardwood') \n",
    "\n",
    "sit_classifiers = pd.DataFrame(data)\n",
    "sit_classifiers.to_csv('data_cbm/sit_classifiers.csv', index=False)\n",
    "sit_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac71fb7-03a7-4db4-b198-701215fe0a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {'id':['harvest', 'fire','f11','f12','f13','f14','f15','f16','f17','f21','f22','f23','f24','f25','f26','f31','f32','f33','f34','f35'], \n",
    "        'name':['harvest', 'fire','plant','plant','plant','plant','plant','plant','plant','plant','plant','plant','plant','plant','plant','plant','plant','plant','plant','plant']}\n",
    "sit_disturbance_types = pd.DataFrame(data)\n",
    "sit_disturbance_types.to_csv('data_cbm/sit_disturbance_types.csv', index=False)\n",
    "sit_disturbance_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bff0bd-d9f7-4606-abca-b8013140aa4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = {'name':['age_0'],\n",
    "#         'class_size':[0],\n",
    "#         'start_year':[0],\n",
    "#         'end_year':[0]}\n",
    "# max_age = 100\n",
    "# for i, ac in enumerate(range(period_length, max_age+period_length, period_length)):\n",
    "#     data['name'].append('age_%i' % (i+1))\n",
    "#     data['class_size'].append(period_length)\n",
    "#     data['start_year'].append(ac - period_length + 1)\n",
    "#     data['end_year'].append(ac)\n",
    "# sit_age_classes = pd.DataFrame(data)\n",
    "# sit_age_classes.to_csv('data_cbm/sit_age_classes.csv', index=False)\n",
    "# sit_age_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa8f73-875a-47e2-8434-65b94ac0e514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# age class test\n",
    "sit_age_classes = pd.read_csv('data/libcbm_model_files/sit_age_classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95718b33-ce68-45d4-8e2b-c19d43ac5ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = ['theme0',\n",
    "           'theme1',\n",
    "           'theme2',\n",
    "           'theme3',\n",
    "           'theme4',\n",
    "           species_classifier_colname,\n",
    "           'using_age_class',\n",
    "           'min_softwood_age',\n",
    "           'max_softwood_age',\n",
    "           'min_hardwood_age',\n",
    "           'max_hardwood_age',\n",
    "           'MinYearsSinceDist',\n",
    "           'MaxYearsSinceDist',\n",
    "           'LastDistTypeID',\n",
    "           'MinTotBiomassC',\n",
    "           'MaxTotBiomassC',\n",
    "           'MinSWMerchBiomassC',\n",
    "           'MaxSWMerchBiomassC',\n",
    "           'MinHWMerchBiomassC',\n",
    "           'MaxHWMerchBiomassC',\n",
    "           'MinTotalStemSnagC',\n",
    "           'MaxTotalStemSnagC',\t\n",
    "           'MinSWStemSnagC',\n",
    "           'MaxSWStemSnagC',\n",
    "           'MinHWStemSnagC',\n",
    "           'MaxHWStemSnagC',\n",
    "           'MinTotalStemSnagMerchC',\n",
    "           'MaxTotalStemSnagMerchC',\n",
    "           'MinSWMerchStemSnagC',\n",
    "           'MaxSWMerchStemSnagC',\n",
    "           'MinHWMerchStemSnagC',\n",
    "           'MaxHWMerchStemSnagC',\n",
    "           'efficiency',\n",
    "           'sort_type',\n",
    "           'target_type',\n",
    "           'target',\n",
    "           'disturbance_type',\n",
    "           'disturbance_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5bb29d-3727-4df8-a673-8b3640ef1e62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {c:[] for c in columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ea99d-59e9-42ef-a52b-7ff1c1a5de13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# for dtype_key, age, area, acode, period, _ in sch:\n",
    "#     for i in range(5): data['theme%i' % i].append(dtype_key[i])\n",
    "#     data[species_classifier_colname].append(_leading_species(dtype_key))\n",
    "#     data['using_age_class'].append('FALSE')\n",
    "#     data['min_softwood_age'].append(-1)\n",
    "#     data['max_softwood_age'].append(-1)\n",
    "#     data['min_hardwood_age'].append(-1)\n",
    "#     data['max_hardwood_age'].append(-1)\n",
    "#     for c in columns[11:-6]: data[c].append(-1)\n",
    "#     data['efficiency'].append(1)\n",
    "#     data['sort_type'].append(3) # oldest first (see Table 3-3 in the CBM-CFS3 user guide)\n",
    "#     data['target_type'].append('A') # area target\n",
    "#     data['target'].append(area)\n",
    "#     data['disturbance_type'].append(acode)\n",
    "#     data['disturbance_year'].append(period*fm.period_length*10)\n",
    "# sit_events = pd.DataFrame(data)\n",
    "# sit_events.loc[sit_events['disturbance_type'] == 'cc', 'disturbance_type'] = 'harvest'\n",
    "# sit_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964bae13-81e5-4a51-bb95-ef75dbd34453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for dtype_key, age, area, acode, period, _ in sch:\n",
    "    for i in range(5): data['theme%i' % i].append(dtype_key[i])\n",
    "    data[species_classifier_colname].append(_leading_species(dtype_key))\n",
    "    data['using_age_class'].append('FALSE')\n",
    "    data['min_softwood_age'].append((age)*10-1)\n",
    "    data['max_softwood_age'].append((age)*10+1)\n",
    "    data['min_hardwood_age'].append(-1)\n",
    "    data['max_hardwood_age'].append(-1)\n",
    "    data['MinYearsSinceDist'].append(-1)\n",
    "    data['MaxYearsSinceDist'].append(-1)\n",
    "    for c in columns[13:-6]: data[c].append(-1)\n",
    "    data['efficiency'].append(1)\n",
    "    data['sort_type'].append(2) \n",
    "    data['target_type'].append('A') # area target\n",
    "    data['target'].append(area)\n",
    "    data['disturbance_type'].append(acode)\n",
    "    data['disturbance_year'].append(period*fm.period_length*10)\n",
    "sit_events = pd.DataFrame(data)\n",
    "sit_events.loc[sit_events['disturbance_type'] == 'cc', 'disturbance_type'] = 'harvest'\n",
    "sit_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391cd06-f755-4b41-bbd8-8049cb64de12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sit_events.to_csv('data_cbm/sit_events.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb3ca90-f66f-4b3b-8d0f-99874e021503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "au_table = pd.read_csv('data/au_table.csv')\n",
    "au_table1 = au_table.set_index('au_id')\n",
    "au_table2 = au_table.set_index('managed_curve_id')\n",
    "# au_table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efd9a01-88bb-4abf-8789-2259a859f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['theme0', 'theme1', 'theme2', 'theme3', 'theme4', species_classifier_colname,\n",
    "           'using_age_class', 'min_softwood_age', 'max_softwood_age', 'min_hardwood_age',\n",
    "           'max_hardwood_age', 'disturbance_type', 'to_theme0', 'to_theme1', 'to_theme2',\n",
    "           'to_theme3', 'to_theme4', 'to_%s' % species_classifier_colname, 'regen_delay',\n",
    "           'reset_age', 'percent']\n",
    "\n",
    "data = {c:[] for c in columns}\n",
    "for acode in fm.transitions:\n",
    "    if acode != 'cc': continue\n",
    "    for smask in fm.transitions[acode]:\n",
    "        tmask, tprop, _, _, _, _, _ = fm.transitions[acode][smask][''][0]\n",
    "        for i in range(5): data['theme%i' % i].append(smask[i])\n",
    "        data[species_classifier_colname].append('softwood' if au_table1.loc[int(smask[2])].canfi_species < 1200 else 'hardwood')\n",
    "        data['using_age_class'].append('FALSE')\n",
    "        data['min_softwood_age'].append(-1)\n",
    "        data['max_softwood_age'].append(-1)\n",
    "        data['min_hardwood_age'].append(-1)\n",
    "        data['max_hardwood_age'].append(-1)\n",
    "        data['disturbance_type'].append('harvest')\n",
    "        for i in range(5): data['to_theme%i' % i].append(tmask[i])\n",
    "        data['to_%s' % species_classifier_colname].append('softwood' if au_table2.loc[int(tmask[4])].canfi_species < 1200 else 'hardwood')\n",
    "        data['regen_delay'].append(0)\n",
    "        data['reset_age'].append(0)\n",
    "        data['percent'].append(100)\n",
    "\n",
    "sit_transitions = pd.DataFrame(data)\n",
    "\n",
    "def add_disturbance_type(disturbance, dataframe):\n",
    "    disturbance_num = int(disturbance[1:])\n",
    "    disturbance_age = int(disturbance[2:])\n",
    "    new_data = {c:[] for c in columns}\n",
    "    for acode in fm.transitions:\n",
    "        if acode != 'cc': continue\n",
    "        for smask in fm.transitions[acode]:\n",
    "            tmask, tprop, _, _, _, _, _ = fm.transitions[acode][smask][''][0]\n",
    "            for i in range(5): new_data['theme%i' % i].append(smask[i])\n",
    "            new_data[species_classifier_colname].append('softwood' if au_table1.loc[int(smask[2])].canfi_species < 1200 else 'hardwood')\n",
    "            new_data['using_age_class'].append('FALSE')\n",
    "            new_data['min_softwood_age'].append(-1)\n",
    "            new_data['max_softwood_age'].append(-1)\n",
    "            new_data['min_hardwood_age'].append(-1)\n",
    "            new_data['max_hardwood_age'].append(-1)\n",
    "            new_data['disturbance_type'].append(disturbance)\n",
    "            for i in range(5): new_data['to_theme%i' % i].append(tmask[i] if i != 4 else int(tmask[i])+disturbance_num*10)\n",
    "            new_data['to_%s' % species_classifier_colname].append('softwood' if au_table2.loc[int(tmask[4])].canfi_species < 1200 else 'hardwood')\n",
    "            new_data['regen_delay'].append(0)\n",
    "            new_data['reset_age'].append(disturbance_age*10)\n",
    "            new_data['percent'].append(100)\n",
    "    new_dataframe = pd.DataFrame(new_data)\n",
    "    return pd.concat([dataframe, new_dataframe])\n",
    "\n",
    "# Now, call the new function for each of the disturbance types you listed\n",
    "for disturbance in ['f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f31', 'f32', 'f33', 'f34', 'f35']:\n",
    "    sit_transitions = add_disturbance_type(disturbance, sit_transitions)\n",
    "\n",
    "sit_transitions.to_csv('data_cbm/sit_transitions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810237a-5897-4a61-874f-7404b4b0d262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sit_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d63ea40-4245-432c-a9bc-2bd925a41f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from libcbm.input.sit import sit_reader\n",
    "from libcbm.input.sit import sit_cbm_factory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730e912-a762-431e-bc12-d1d0ca5a6765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sit_data = None\n",
    "sit_yield.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb89fab-b16c-4342-b8f3-d108a872c1e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sit_data = sit_reader.parse(sit_classifiers=sit_classifiers,\n",
    "                            sit_disturbance_types=sit_disturbance_types,\n",
    "                            sit_age_classes=sit_age_classes,\n",
    "                            sit_inventory=sit_inventory,\n",
    "                            sit_yield=sit_yield,\n",
    "                            sit_events=sit_events,\n",
    "                            sit_transitions=sit_transitions,\n",
    "                            sit_eligibilities=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7def5-110a-4a82-81e2-e89bf8278efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sit_config = {\n",
    "    'mapping_config': {\n",
    "        'nonforest': None,\n",
    "        'species': {\n",
    "            'species_classifier': species_classifier_colname,\n",
    "            'species_mapping': [\n",
    "                {'user_species': 'softwood', 'default_species': 'Softwood forest type'},\n",
    "                {'user_species': 'hardwood', 'default_species': 'Hardwood forest type'}\n",
    "            ]\n",
    "        },\n",
    "        'spatial_units': {\n",
    "            'mapping_mode': 'SingleDefaultSpatialUnit',\n",
    "            'admin_boundary': 'British Columbia',\n",
    "            'eco_boundary': 'Montane Cordillera'},\n",
    "        'disturbance_types': {\n",
    "            'disturbance_type_mapping': [\n",
    "                {'user_dist_type': 'harvest', 'default_dist_type': 'Clearcut harvesting without salvage'},\n",
    "                {'user_dist_type': 'fire', 'default_dist_type': 'Wildfire'},\n",
    "                {'user_dist_type': 'plant', 'default_dist_type': 'Planting'},\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f8529-9fbc-4075-bfb5-752d4f881a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sit = sit_cbm_factory.initialize_sit(sit_data=sit_data, config=sit_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9c774-7a5b-4871-8022-266f40a61101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers, inventory = sit_cbm_factory.initialize_inventory(sit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8585357e-ecba-4870-9dd5-3332556f6979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3343ebc-480f-4938-9db6-e080960c5df5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from libcbm.model.cbm.cbm_output import CBMOutput\n",
    "\n",
    "cbm_output = CBMOutput(\n",
    "    classifier_map=sit.classifier_value_names,\n",
    "    disturbance_type_map=sit.disturbance_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89053e97-dc9d-4ecd-aa71-89436c577075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from libcbm.storage.backends import BackendType\n",
    "from libcbm.model.cbm import cbm_simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcea683-ea6e-4691-b905-7af4bffa6e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with sit_cbm_factory.initialize_cbm(sit) as cbm:\n",
    "    # Create a function to apply rule based disturbance events and transition rules based on the SIT input\n",
    "    rule_based_processor = sit_cbm_factory.create_sit_rule_based_processor(sit, cbm)\n",
    "    # The following line of code spins up the CBM inventory and runs it through 200 timesteps.\n",
    "    cbm_simulator.simulate(\n",
    "        cbm,\n",
    "        n_steps              = 200,\n",
    "        classifiers          = classifiers,\n",
    "        inventory            = inventory,\n",
    "        pre_dynamics_func    = rule_based_processor.pre_dynamics_func,\n",
    "        reporting_func       = cbm_output.append_simulation_result,\n",
    "        backend_type = BackendType.numpy\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c862146a-7085-4fdf-946b-1890702afd33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pi = cbm_output.classifiers.to_pandas().merge(cbm_output.pools.to_pandas(), left_on=[\"identifier\", \"timestep\"], right_on=[\"identifier\", \"timestep\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75266d4-2652-4c7b-9e55-17c5ab8e980e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8966f-3aca-41a0-b26d-5613e91dd35e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pi.to_csv('model_result/pool_inventory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d64e84-cf34-4bba-a1dc-58a99db39c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# si = cbm_output.cbm_vars.state.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02906cf-085a-4a4b-8359-8e89f923eca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pi.head()\n",
    "column_name = pi.columns\n",
    "column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c72947-38cb-4afc-98a5-3b99aac42223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emission_pools = ['CO2', 'CH4', 'CO', 'NO2']\n",
    "\n",
    "emission_result = pi[['timestep']+emission_pools]\n",
    "# dom_result = pi[['timestep']+dom_pools]\n",
    "# total_eco_result = pi[['timestep']+biomass_pools+dom_pools]\n",
    "\n",
    "biomass_pools = ['SoftwoodMerch','SoftwoodFoliage', 'SoftwoodOther', 'SoftwoodCoarseRoots', 'SoftwoodFineRoots',\n",
    "                 'HardwoodMerch', 'HardwoodFoliage', 'HardwoodOther', 'HardwoodCoarseRoots', 'HardwoodFineRoots']\n",
    "\n",
    "\n",
    "annual_emission_stocks = pd.DataFrame(\n",
    "    {\n",
    "        \"Year\": pi[\"timestep\"],\n",
    "        \"Emission\": pi[biomass_pools].sum(axis=1),})\n",
    "\n",
    "annual_emission_stocks\n",
    "# annual_emission_stocks.groupby(\"Year\").sum().plot(figsize=(10,10),xlim=(0,160),ylim=(0,None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656beaff-a3b4-4c0a-b463-89b2d65cea45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "biomass_pools = ['SoftwoodMerch','SoftwoodFoliage', 'SoftwoodOther', 'SoftwoodCoarseRoots', 'SoftwoodFineRoots',\n",
    "                 'HardwoodMerch', 'HardwoodFoliage', 'HardwoodOther', 'HardwoodCoarseRoots', 'HardwoodFineRoots']\n",
    "\n",
    "pi[[\"timestep\"]+biomass_pools].groupby(\"timestep\").sum().plot(figsize=(15,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665d6cb-53b0-4039-9d14-6139daa66083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "biomass_pools = ['SoftwoodFoliage', 'SoftwoodOther', 'SoftwoodCoarseRoots', 'SoftwoodFineRoots',\n",
    "                 'HardwoodFoliage', 'HardwoodOther', 'HardwoodCoarseRoots', 'HardwoodFineRoots']\n",
    "\n",
    "dom_pools = ['AboveGroundVeryFastSoil', 'BelowGroundVeryFastSoil', 'AboveGroundFastSoil', 'BelowGroundFastSoil',\n",
    "             'MediumSoil', 'AboveGroundSlowSoil', 'BelowGroundSlowSoil', 'SoftwoodStemSnag', 'SoftwoodBranchSnag',\n",
    "             'HardwoodStemSnag', 'HardwoodBranchSnag']\n",
    "\n",
    "biomass_result = pi[['timestep']+biomass_pools]\n",
    "dom_result = pi[['timestep']+dom_pools]\n",
    "total_eco_result = pi[['timestep']+biomass_pools+dom_pools]\n",
    "\n",
    "annual_carbon_stocks = pd.DataFrame(\n",
    "    {\n",
    "        \"Year\": pi[\"timestep\"],\n",
    "        \"Biomass\": pi[biomass_pools].sum(axis=1),\n",
    "        \"DOM\": pi[dom_pools].sum(axis=1),\n",
    "        \"Total Ecosystem\": pi[biomass_pools+dom_pools].sum(axis=1)})\n",
    "\n",
    "annual_carbon_stocks.groupby(\"Year\").sum().plot(figsize=(10,10),xlim=(0,160),ylim=(0,None))\n",
    "\n",
    "annual_carbon_stocks_year = annual_carbon_stocks.groupby(\"Year\").sum().reset_index()\n",
    "\n",
    "ecosystem_emission = {'period': [], 'co2_ecosystem_emission': []}\n",
    "\n",
    "# ecosystem_dynamic = annual_carbon_stocks_year.groupby('period')['Total Ecosystem'].sum().reset_index()\n",
    "\n",
    "for i in range(0,20):\n",
    "    ecosystem_emission['period'].append(i+1)\n",
    "    ecosystem_emission['co2_ecosystem_emission'].append(annual_carbon_stocks_year['Total Ecosystem'].loc[i*10]-annual_carbon_stocks_year['Total Ecosystem'].loc[(i+1)*10])\n",
    "    \n",
    "\n",
    "    \n",
    "df_ecosystem_emission = pd.DataFrame(ecosystem_emission)\n",
    "df_ecosystem_emission['co2_ecosystem_emission'] = df_ecosystem_emission['co2_ecosystem_emission'] * 1000 * 44 / 12 # 1000 is convert t of c to kg of c, and what's the unit of emission\n",
    "\n",
    "df_ecosystem_emission\n",
    "# annual_carbon_stocks_year.head(31)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da782fe-233d-4076-a2b6-53938728327b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annual_carbon_stocks_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dcdd7e-89f1-45d0-806b-5510eb5ac7c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "si = cbm_output.state.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0409ffa-ace4-4b53-b75c-094326d25ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157a1001-5229-46f2-b499-032b3d90644e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data = cbm_output.classifiers.to_pandas().merge(\n",
    "    cbm_output.pools.to_pandas(),\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ").merge(\n",
    "    cbm_output.state.to_pandas(),\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "# half = len(merged_data) // 2\n",
    "# df_first_half = merged_data.iloc[:half]\n",
    "# df_first_half.to_csv('model_result/cbm_flux/pool_inventory_half.csv.gz',compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8084f38-e916-4b7c-952e-b2d796391703",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d9b55-6ad0-44fc-99a6-5f3e4a54a9a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annual_state = pd.DataFrame(\n",
    "    {\n",
    "        \"Year\": merged_data[\"timestep\"],\n",
    "        \"AU\": merged_data[\"theme4\"],\n",
    "        \"age\": merged_data[\"time_since_last_disturbance\"]})\n",
    "\n",
    "annual_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce512a7-838c-46a4-a2d0-038766fdfb0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fi = cbm_output.flux.to_pandas()\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae4c2f6-506c-4bb6-abfb-481a6bedb6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fi.to_csv('model_result/cbm_flux/flux.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7161fe3-6a32-4f56-9f6f-9dd07c044212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new 'year' column\n",
    "fi['year'] = fi['timestep']\n",
    "\n",
    "emission_columns = [\n",
    "    'DecayVFastAGToAir',\n",
    "    'DecayVFastBGToAir',\n",
    "    'DecayFastAGToAir',\n",
    "    'DecayFastBGToAir',\n",
    "    'DecayMediumToAir',\n",
    "    'DecaySlowAGToAir',\n",
    "    'DecaySlowBGToAir',\n",
    "    'DecaySWStemSnagToAir',\n",
    "    'DecaySWBranchSnagToAir',\n",
    "    'DecayHWStemSnagToAir',\n",
    "    'DecayHWBranchSnagToAir'\n",
    "]\n",
    "\n",
    "# Create a new 'total_decay' column that is the sum of the decay columns\n",
    "fi['total_decay'] = fi[emission_columns].sum(axis=1)\n",
    "\n",
    "df_eco_decay = fi[['total_decay', 'year']].groupby('year').sum()\n",
    "\n",
    "# Convert the DataFrame where 'year' is a column instead of an index\n",
    "df_eco_decay = df_eco_decay.reset_index()\n",
    "\n",
    "initial_emission = df_eco_decay[df_eco_decay['year'] == 1]['total_decay'].values[0]\n",
    "\n",
    "# Create new column 'dom_emission'\n",
    "df_eco_decay['dom_emission'] = df_eco_decay['total_decay'] - initial_emission\n",
    "df_eco_decay['co2_dom_emission'] = df_eco_decay['dom_emission'] * 1000 * 44 / 12 \n",
    "\n",
    "df_eco_decay\n",
    "\n",
    "df_eco_decay['period'] = (df_eco_decay['year'] // 10) * 10\n",
    "\n",
    "df_eco_emission = df_eco_decay.groupby('period')['co2_dom_emission'].sum().reset_index()\n",
    "\n",
    "df_eco_emission = df_eco_emission[df_eco_emission['period'] != 0].reset_index(drop=True)\n",
    "\n",
    "# df_eco_decay\n",
    "df_eco_emission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a19cb-68a4-4bf4-b2c3-8111a487d30d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annual_process_fluxes = [\n",
    "    # 'DecayDOMCO2Emission',\n",
    "    # 'DeltaBiomass_AG',\n",
    "    # 'DeltaBiomass_BG',\n",
    "    # 'TurnoverMerchLitterInput',\n",
    "    # 'TurnoverFolLitterInput',\n",
    "    # 'TurnoverOthLitterInput',\n",
    "    # 'TurnoverCoarseLitterInput',\n",
    "    # 'TurnoverFineLitterInput',\n",
    "    'DecayVFastAGToAir',\n",
    "    'DecayVFastBGToAir',\n",
    "    'DecayFastAGToAir',\n",
    "    'DecayFastBGToAir',\n",
    "    'DecayMediumToAir',\n",
    "    'DecaySlowAGToAir',\n",
    "    'DecaySlowBGToAir',\n",
    "    'DecaySWStemSnagToAir',\n",
    "    'DecaySWBranchSnagToAir',\n",
    "    'DecayHWStemSnagToAir',\n",
    "    'DecayHWBranchSnagToAir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf711b-6673-43de-8efc-f378118b5bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fi[[\"timestep\"]+annual_process_fluxes].groupby(\"timestep\").sum().plot(figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6bba12-1acc-4eee-a89c-b26e3ba2c2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_based_processor.sit_event_stats_by_timestep[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3dee56-f296-43b5-8f41-05bd4b0982a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_based_processor.sit_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f1662-d84f-4d1f-bac7-0ca589caed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emission_calculation = df_product[['period']].join([df_product.drop('period', axis=1),\n",
    "                                                       df_operation_area.drop('period', axis=1),\n",
    "                                                       df_carbon_seq.drop('period', axis=1),\n",
    "                                                       df_ecosystem_emission.drop('period', axis=1),\n",
    "                                                       df_eco_emission.drop('period', axis=1)])\n",
    "\n",
    "df_emission_calculation.to_csv(f\"model_result/emission_calculation/emission_calculation_{model_name}_{scenario_name}_{float(inventory_retention)}.csv\")\n",
    "print(f\"model_result/emission_calculation/emission_calculation_{model_name}_{scenario_name}_{float(inventory_retention)}.csv\")\n",
    "df_emission_calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdcc00e-78af-4dad-a62d-8b6bb3663121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b13f42-062b-40a2-aa7b-4c0e76235c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
